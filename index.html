<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Language" content="en-us" />
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii" />
  <link rel="stylesheet" type="text/css" href=
  "../../../doc/src/boostbook.css" />

  <title>Libary Status</title>
  <style type="text/css">
/*<![CDATA[*/
  span.c3 {color: #FF0000; font-style: italic}
  a.c2 {font-style: italic}
  td.c1 {font-style: italic}
  /*]]>*/
  </style>
</head>

<body>
  <table border="0">
    <tr>
      <td><img border="0" src="../../../boost.png" width="277" height="86"
      alt="boost.png (6897 bytes)" /></td>

      <td>
        <h1>Generating Library Status Tables</h1>
      </td>
    </tr>
  </table>

  <h3>Purpose</h3>Any time one considers using a library as large and complex
  as the Boost libraries, he must have a way of validating the the library
  functions in his environment. This should be done when the library is
  installed and anytime questions are raised regarding its applicability
  and/or its usage.

  <p>The procedures described here permit a user to run any combination of
  tests on any or all libraries and generate a set of convenient tables which
  show which libraries pass which tests under what conditions.</p>

  <h3>Preliminaries</h3>Generating these tables requires a couple of utility
  programs: <code>process_jam_log</code> and <code>library_status</code>.
  These can be built by moving to the directory
  <code>tools/regression/build</code> and invoking bjam. If all goes well
  these utility programs will be found in the directory
  <code>dist/bin</code>. From there they should be moved to a place in the
  current path.

  <h3>Running Tests for One Library</h3>

  <ol>
    <li>Start from your command line environment.</li>

    <li>set the current directory to:../libs/&lt;library name&gt;/test</li>

    <li>Invoke one of the following:

      <ul>
        <li><code>../../../tools/regression/src/library_test (*nix)</code>.</li>

        <li><code>..\..\..\tools\regression\src\library_test
        (windows)</code>.</li>
      </ul>
    </li>

    <li>This will display short help message describing the how to set the
    command line arguments for the compilers and variants you want to appear
    in the final table.</li>

    <li>Setting these arguments requires rudimentary knowledge of bjam usage.
    Hopefully, if you've arrived at this page you've gained the required
    knowledge during the installation and library build process.</li>

    <li>Rerun the abve command with the argument set accordingly.</li>

    <li>When the command terminates, there should be a file named
    "library_status.html" in the current directory.</li>

    <li>Display this file with any web browser.</li>
  </ol>There should appear a table similar to the following for the serialization
  library.

<object data="library_status.html" width=100% height=1000 >
Warning: library_status.html could not be included.
</object>

  <p>This table was generated by invoking the following command line
  from within the .../libs/serialization/test directory:</p>

  <p><code>../../../tools/regression/src/library_test --toolset=clang-darwin-03,clang-darwin-11,darwin4.9 address-model=64,32 link=static,shared
  variant=debug,release</code></p>

  <p>It shows all the combinations for test configurations run.  As
  more tests are run the table gets longer.  As more conigurations are run, the
  table gets wider. The cells marked "Missing" correspond to tests that were
  not run for some reason or another. This is usually because the
  corresponding <code>Jamfile.v2</code> excludes this test for the given
  combination of compiler and build attributes.

  <p>Tables are cumulative. That is, if you run one set of tests now and
  tests with different attributes later, the table will contain all the
  results to date. The test results are stored in
  <code>../bin.v2/libs/test/&lt;library%gt;/...</code>. To reinitialize the
  test results to empty, delete the corresponding files in this
  directory.</p>

  <p>The procedure above assumes that the table are generated within the
  directory <code>../libs/&lt;library&gt;/test</code>. This is the most
  common case since this directory contains the <code>Jamfile.v2</code> as
  well as the source code that is used by official boost testers. However,
  this is just a convention. The table can be generated for other directories
  within the libary. One possibility would be to generate the table for all
  the examples in <code>../libs/%lt;library%gt;/example</code>. Or one might
  have a special directory of performance tests which take a long time to run
  and hence are not suitable for running by official boost testers. Just
  remember that library status table is generated in the directory from which
  the <code>library_test</code> command is invoked.</p>

  <h3>Running Tests for All Libraries</h3>For those with *nix or cygwin
  command line shells, there is shell script that can be run from the boost
  root directory:

  <p><code>tools/regression/src/library_test_all</code></p>

  <p>The command line arguments are the same as for running the test for one
  library. This script creates all the html files in all the test directories
  as well as an html page in the <code>status</code> directory named
  <code>library_status_summary.html</code>. This can be used to browse
  through all test results for all test in all libraries.</p>
  <hr />


  <p>Copyright 2011 Bryce Lelbach.</p>
  <p>Copyright 2007-2015 Robert Ramey.</p>

  <p>Distributed under the Boost Software
  License, Version 1.0. (See accompanying file LICENSE_1_0.txt or
  http://www.boost.org/LICENSE_1_0.txt)</p>

  <p>Revised $Date$</p>
</body>
</html>
